# Архитектура и формирование агентности в LLM

Агентность в больших языковых моделях (LLM) — это способность системы замыкать цикл взаимодействия с внешней средой: **наблюдение → план → действие → новое наблюдение → корректировка → остановка**. Развитие этой способности представляет собой не бинарный переключатель, а градиент, формирующийся на разных этапах обучения модели.

---

## 1. Фазы развития агентности

Формирование агентных способностей распределено по трем основным этапам обучения:

| Фаза | Роль в формировании агентности | Результат |
| --- | --- | --- |
| **Pre-training** | Накопление «сырых» знаний, логики и понимания кода.

 | <br>**Потенциал:** Способность понимать мир и инструкции. Закладывается статистическая вероятность агентного поведения.

 |
| **Mid-training** | Кристаллизация навыков через траектории рассуждений (traces) и работу с инструментами.

 | <br>**Рассуждение:** Умение строить маршрут решения и планировать. Формируется «операциональная семантика» действий.

 |
| **Post-training / RL** | Активация автономии, обучение через обратную связь и самокоррекцию.

 | <br>**Надежность:** Исполнительность, точное следование протоколам и интерфейсам (JSON, MCP).

 |

---

## 2. Роль Mid-training и данных

Mid-training (или Continued Pre-training) является критическим этапом для доменной адаптации и усиления латентных способностей.

* 
**Data Mixing:** Оптимальная пропорция данных для этого этапа включает 40–50% агентных данных (цепочки рассуждений), 20–30% сложного кода и качественный текст для связности.


* 
**Значение кода:** Обучение на программном коде критично, так как он по своей природе агентен: содержит логику «вход → обработка → выход» и сценарии обработки ошибок.


* 
**Scaling Laws:** В агентных системах открыто новое измерение масштабирования: производительность улучшается пропорционально частоте и эффективности взаимодействия агента со средой (количеству tool calls).



---

## 3. Условия возникновения агентности

Агентность проявляется как фазовое пересечение при выполнении трех условий:

1. 
**Компетентность:** Достаточный масштаб модели и база знаний (Pre-training).


2. 
**Операциональные примитивы:** Понимание того, что действия меняют наблюдения (Mid-training на трассах tool use).


3. 
**Селектор поведения:** Выбор долгого цикла рассуждений вместо быстрого ответа (RL/RLHF).



Дополнительным «4-м множителем» выступает **интерфейс и среда** (ACIs, инструменты, ограничения), которые могут влиять на агентность сильнее, чем параметры базовой модели.

---

## 4. Ограничения и альтернативные подходы

Исследования (например, APTBench) показывают, что агентные способности могут проявляться уже на этапе pre-training, а последующие фазы лишь «проявляют» их.

* 
**Проблемы:** Основные сбои в агентном поведении происходят из-за «размазывания» ошибок ранних этапов на длинных цепочках действий и плохой способности моделей к восстановлению (recovery) после ошибок.


* 
**Псевдо-RL:** Агентность можно эффективно наращивать без обновления весов (дорогого RL) через архитектурные решения: вербальную обратную связь (Reflexion), автоматические учебные планы (curriculum) и библиотеки навыков (Voyager).



---

Хотите, чтобы я подробнее разобрал конкретную фазу обучения или специфику формирования данных (Data Mixing) для агентных моделей?
